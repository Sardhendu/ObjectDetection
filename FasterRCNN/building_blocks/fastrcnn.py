'''

ROI Pooling:
Up until now we have performed:
    1. Convolution to generate feature map
    2. RPN to extract region proposals.
    3. Proposal with box transformation to find the top bounding boxes

This module: Region based object detection (Fast RCNN): Now given that we have the bounding boxes (can have different
numbers for different image), we need to classify the bounding box. i.e if the bounding box contains a person in it or a cat or a dog etc.

The awesomeness of FasterRCNN lies in the idea that we can perform joint training of RPN and FastRCNN and hence
backpropagate through the whole network instead of doing in steps. This reduces the run time by about 25-50% since
the whole convolutional operation to generate the feature map is shared across both the RPN anf FastRCNN modules.

'''
import numpy as np
import tensorflow as tf

def roi_pool(feature_map, proposals, image_shape):
    '''
    Understand what going underneath
    
    Why switch dimensions
    The Proposals as of now have a shape of [bottom_left_x, bottom_left_y, upper_right_x, upper_right_y],
    but when treating images they should take the form [bottom_left_y, bottom_left_x, upper_right_y, upper_right_x]
    Here we make the switch.
    
    Related Idea
    The FastRCNN paper says that the feature map from the convolutional layers are passed down to the ROI pooling
    layer where the feature map are further pooled (downsampled) to a smaller and fixed spatial extent i.e. 7x7.
    
    Whay ROI POOL: The idea is to classify each proposals, suppose we have 100 proposals. A prerequisite to the
    classification is a 7x7 roi pool.
        1. First we crop all the proposals from the feature map, resize the proposals to 14x14. In case if the
           proposal < 14x14 then we perform bi-linear transformation to upscale to 14x14, In case if the
           proposal shape > 14x14 then we crop.  Output = [num_proposals x 14 x 14 x feature_map_channels]
        2. Then we max pool each proposals and convert them to 7x7, Output=[num_proposals x 7 x 7 x feature_map_channels]
    
    Why do we Normalize:
    Since we perform all the operation in feature map we would want to return to the normalized or scaled (0-1) range dimension.
    Also, when using tensorflow in order to crop_and_resize, it is required to have the coordinates in normalized form.
    
    :param feature_map:  Feature maps as a result of convolutions with VGG
    :param proposals:    Proposals garnered after RPN and proposals
    :param image_shape:
    :return:
    '''
    image_shape = np.array(image_shape, dtype='float32')

    box_ind = np.zeros(proposals.shape[0])
    box_ind = tf.cast(box_ind, dtype=tf.int32)
    boxes = proposals#[:,1:]
    print (boxes.dtype, image_shape.dtype)
    
    # Change xy dimensions
    boxes = tf.stack([boxes[:,1], boxes[:,0], boxes[:,3], boxes[:,2]], axis=1)
    
    # Normalize the bounding boxes (proposals)
    image_shape_tf = tf.cast(tf.stack([image_shape[0], image_shape[1], image_shape[0], image_shape[1]], axis=0),
                             dtype=tf.float32)
    image_shape_tf = tf.reshape(image_shape_tf, [1,image_shape_tf.shape[0]])
    boxes = tf.div(boxes, image_shape_tf, name='normalized_boxes')
    print(image_shape_tf.shape, boxes.shape)
    
    # Pool Feature map
    crop_size = tf.constant([14,14])
    feature_map = tf.image.crop_and_resize(image=feature_map, boxes=boxes, box_ind=box_ind, crop_size=crop_size)
    pooled_feature_map = tf.layers.max_pooling2d(feature_map, pool_size=2, strides=2, padding='SAME')
    print (pooled_feature_map.shape)
    return pooled_feature_map
    


class FastRCNN():
    '''
    FastRCNN in general, is a network that takes input the Proposals. These Proposals are generated using selective
    search. It then perform convolution operation on the Proposals to classify the object in the Proposal boundary.
    
    IN FasterRCNN however, we don't use selective search to generate Proposals but instead use the Region Proposal
    Network (RPN) using the feature map generated by convolution operation. The post RPN generates the Proposals to
    be used by the FastRCNN network. Also the feature map generated is again used by the FastRCNN network to classify the objects in the proposed region. This enables a lot of parameter sharing across both the RPN and the FastRCNN
    network
    '''
    def __init__(self, feature_map, proposals):
        pass
    
    def build(self):
        '''
        What does the network say:
        
        
        :return:
        '''
    

feature_map = np.array(np.random.random((1,14,14,512)),dtype='float32')
proposals = np.array(np.random.random((100,4)), dtype='float32')
image_shape = np.array([224,224,3])
roi_pool(feature_map, proposals, image_shape)